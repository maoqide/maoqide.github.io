[
{
	"uri": "/algorithm/basic-data-structure/",
	"title": "Basic Data Structure",
	"tags": [],
	"description": "",
	"content": " Array 数组 是线性表数据结构。用一组连续存储空间，储存一组相同类型的数据。支持随机访问 O(1)。\n低效插入和删除 O(n)，需要数据搬移。优化：删除操作延后(JVM垃圾回收算法)。\nLinked list 链表 插入删除 O(1)，随机访问O(n)。\n单链表：插入删除时需要查找前驱节点 O(n)。\n双向链表：插入删除时查找前驱结点 O(1)。\n链表代码实现 单链表字符串回文判断\n 单链表反转\n 链表中环的检测\n 两个有序的链表合并 删除链表倒数第 n 个结点 求链表中间节点  Stack 栈 后进先出，先进后出。入栈出栈 O(1)\n顺序栈：数组。动态扩容（动态扩容数组，数据搬移O(n)）\n链式栈：链表。\nArrayStack 实现 LinkedListStack 实现\n  Queue 队列 先进先出，后进后出。 入队出队O(1)\n数组实现(数据搬移) 链表实现 循环链表数组实现  Skip list 跳表 链表加多级索引的数据结构。查找 O(logn)。Redis 中有序集合 Sorted Set 用跳表实现。\n插入删除 O(logn)。 平衡性维护-随机函数。\n实现   Hash Table 散列表 通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。支持随机访问 O(1)。\n散列函数。\n装载因子 = 填入表中的元素个数 / 散列表的长度\n解决散列冲突：\n- 开放寻址法\n优点：可以有效利用CPU缓存加快查询速度；便于序列化。\n缺点：删除时不能直接删除，需要特使标记已删除的数据；冲突代价高。\n- 线性探测(ThreadLocalMap)：当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。(hash(key)+n)\n- 二次探测：hash(key)+n^2\n- 双重散列：使用多组散列函数(hash1(key)，hash2(key)，hash3(key))\n- 链表法(LinkedHashMap)\n优点：内存利用率高，链表节点不需要提前申请；大装载因子容忍度高。\n缺点：CPU缓存不友好；由于要存储指针，存储小对象时内存消耗大。\n动态扩容：避免一次性搬移大量数据。扩容时只申请新空间，新的数据插入新的散列表，同时将小部分老数据搬移至新散列表，将扩容消耗均摊至每次插入。\n散列表+双向链表 查找删除添加 O(1):\n\u0026gt; LRU 缓存淘汰算法/Redis 有序集合/Java LinkedHashMap\n散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中。一个链是刚刚我们提到的双向链表，另一个链是散列表中的拉链。前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。\n哈希算法：\n将任意长度的二进制值串映射为固定长度的二进制值串的算法。\n应用：\n1. 安全加密(MD5/SHA/AES)\n2. 唯一标识\n3. 数据校验\n4. 散列函数\n5. 负载均衡(会话粘滞, 对IP或会话ID哈希)\n6. 数据分片(大文件关键词分片)\n7. 分布式存储(机器扩容导致重新计算哈希值，一致性哈希算法)\npractice-code\n"
},
{
	"uri": "/notes/build-blog-with-hugo/",
	"title": "Build Blog With Hugo",
	"tags": [],
	"description": "",
	"content": " documentations https://gohugo.io/getting-started/usage/ https://learn.netlify.com/en/\nsetup  install hugo following offical install guide.\ndownload packages from Hugo Release and put executale file hugo in PATH.\n execute hugo new site sitename, To create a new site. directory structure will like this:\n. ├── archetypes ├── assets ├── config.toml ├── content ├── data ├── layouts ├── static └── themes  download theme from github. unzip the archive and copy files to you site dir, overwriting directory and files of the same name. you can change your website config by changing config.toml.\n wirte you first blog. hugo new content/first.md, will gen a markdown file in content. you can use hugo server -w to start a server locally, and visit localhost:1313 for preview.\n execute hugo, this will gen md files in dir content to html files in dir public.\n put your public directory in a nginx.\n  menu directorys in directory content will display as menu in the left. and file named _index.md is the default page of the directory.\nexample you can visit my github repo hugo-blog, the article itself is generated by this repo.\nchange theme you can change your styles by changing different themes. themes could be found at http://themes.gohugo.io.\noverall overall, you can easily create your own doc/blog by follow command:\n# create a new site hugo new site mysite cd mysite/ # create your first page hugo new first.md # build page hugo  then you can find your site in directory public.\n"
},
{
	"uri": "/collection/",
	"title": "Collection",
	"tags": [],
	"description": "",
	"content": "Collection excellent articles.\n"
},
{
	"uri": "/collection/collection-1/",
	"title": "Collection 1",
	"tags": [],
	"description": "",
	"content": " Mesos 的资源分配，解释 mesos 的二级调度和资源邀约机制，并详细介绍了保证资源分配公平的DRF算法（主导资源公平算法 Dominant Resource Fairness）。\nhttps://www.infoq.cn/article/analyse-mesos-part-04\nbakup_url\n goroutine 调度器解析。\nhttps://tonybai.com/2017/06/23/an-intro-about-goroutine-scheduler/\nbakup_url\n 一致性哈希算法。\nhttps://segmentfault.com/a/1190000013533592\nbakup_url\n Kubernetes调度详解。 http://dockone.io/article/2885 bakup_url\n  "
},
{
	"uri": "/algorithm/",
	"title": "Algorithm",
	"tags": [],
	"description": "",
	"content": " documents about algorithm.\n "
},
{
	"uri": "/cloud/",
	"title": "Cloud",
	"tags": [],
	"description": "",
	"content": " documents about cloud.\nkubernetes/docker\u0026hellip;\n "
},
{
	"uri": "/golang/goroutine/",
	"title": "Goroutine Management In Golang",
	"tags": [],
	"description": "",
	"content": " goroutine 是 go 的最重要特性之一，可以方便的实现并发编程。但是真正用起来，如果不多加注意，很容易造成 goroutine 的泄漏或者脱离管理，造成代码跑一段时间，就是产生大量无法回收的goroutine(可通过 pprof 查看)。最近学习整理了下 go 语言中管理 goroutine 的几种方法和一些最佳实践。\n几点原则 go-best-practices-concurrency\n在 github上的 go-best-practices 项目中，提到了几点最佳实践，这里记录下。\n不要和 goroutine 失去联系(Don\u0026rsquo;t loose contact with your goroutines) 如何避免? 使用make(chan struct{})/sync.WaitGroup/context.Context或select。\n你可能需要这样：\n1. 当必要的时候可以*中断*创建的 goroutine。 2. 等待直到产生的所有 goroutine 都完成了。\n 中断(Interruption)\n可以用以下方式实现： 共享一个无缓冲的空结构体通道（make（chan struct {}）），由 goroutine 的创建者发出关闭信号以关闭。 一个可取消的context.Context。 确保你的 goroutine 使用select来不时检查他们的信号，而不会无限期地阻塞住。\n 等待 goroutine 完成(Waiting for goroutines to finish)\n实现的最简单方法是使用sync.WaitGroup。在创建 goroutine 之前，请确保调用了wg.Add(1)。在运行 goroutine 之后，但在它 return 之前，请确保wg.Done()。这种场景下，defer是很好的选择。\n  不要用 WaitGroup 来计数多种类型的 goroutine(Don\u0026rsquo;t use wait groups to count more than one type of goroutine) 这里说的 gouroutine 的类型和被作为 gouroutine 调用的函数相关联，此函数可以是另一种类型的成员函数，可以是包中的命名函数，也可以是匿名函数。重要的一点是，你不应该在作为goroutine 调用的不同函数之间共享 WaitGroup。保持简单，如果你需要对一个不同类型的函数使用go关键字，创建一个新的 WaitGroup，并对它正确命名。\ntype Parent struct { wgFoo sync.WaitGroup wgBar sync.WaitGroup } func (p *Parent) foo() { defer p.wgFoo.Done() } func (p *Parent) bar() { defer p.wgBar.Done() } func (p *Parent) Go() { p.wgFoo.Add(1) go p.foo() p.wgBar.Add(1) go.bar() }  虽然共享一个 WaitGroup 可能是正确的解决方案，但是当下一位工程师接受时，它会增加问题的认知复杂性。\n不要让一个 channel 的消费者说什么时候结束(Don\u0026rsquo;t let a channel consumer say when it is done)  对一个已关闭的 channel 发送会导致 panic\n 首先且最重要的是，代码实现是 channel 的消费者和生产者模型，这本身就是一种很好的做法。这是一个明显的关注点分离。\ngolang 给你在编译时定义一个 channel 的方向的能力recvOnly \u0026lt;-chan Thing := make(chan Thing)。这在定义变量时很少有用，但是，在定义函数的接收参数时非常有用。比如：\nfunc consume(things \u0026lt;-chan Thing) { // will do work until close for thing := range things { // do work } }  这强制（在编译时）消费者 goroutine 无法在对 channel 发送数据，包括关闭该 channel 的能力。\n这强制顶一个租户(goroutine)安全管理 channel。只有当所有生产者停止发送，才关闭 channel。谨记对一个已关闭的 channel 发送会导致 panic。\n关闭 channel 的代码必须选保证不会再对此 channel 发送(The piece of code which closes a channel must first guarantee that nothing else will produce on it).\n如果所有对 channel 的发送都在关闭前同步发生，只要你不重试并再次发送，那就是安全的。\n如果该 channel 上的生产(production)被放弃到其他 goroutine，那么你需要能够与这些 goroutine 同步退出。\n如果我们可以保证对 goroutine 进行计数并等待它们退出，那么我们可以确定关闭 channel 不会在其他地方引起 panic。\nfunc doConcurrently() { var ( things = make(chan Thing) finished = make(chan struct{}) wg sync.WaitGroup ) go func() { // will consume until close consume(things) // signal consumption has finished close(finished) }() for i := 0; i \u0026lt; noOfThingsWeWantToDo; i++ { wg.Add(1) go func() { defer wg.Done() things \u0026lt;- Thing{} }() } // wait until all producers have stopped wg.Wait() // then you can close close(things) // wait until finished consuming \u0026lt;-finished }  总结  确保消费者只能消费。使用recvOnly \u0026lt;-chan Thing 。\n 跟踪 gouroutine 的完成。使用sync.WaitGroup。\n 只有在确认生产者 goroutine 不能再对 channel 进行发送的情况下，再关闭channel。\n  从外部结束一个 goroutine [参考]从外部结束一个 goroutine\n可响应 channel 的 goroutine\n\u0026gt; 最直接的方法是关闭与这个 goroutine 通信的 channel close(ch)。如果这个 goroutine 此时阻塞在 read 上，那么阻塞会失效，并在第二个返回值中返回 false (此时可以检测并退出)；如果阻塞在 write 上，那么会 panic，这时合理的做法是在 goroutine 的顶层 recover 并退出。 更健壮的设计一般会把 data channel (用于传递业务逻辑的数据) 和 signal channel (用于管理 goroutine 的状态) 分开。不会让 goroutine 直接读写 data channel，而是通过 select-default 或 select-timeout 来避免完全阻塞，同时周期性地在 signal channel 检查是否有结束的请求。\n不可响应的 goroutine\n\u0026gt; 1. 尽量使用 Non-blocking IO (正如 go runtime 那样)\n\u0026gt; 2. 尽量使用阻塞粒度较小的 sys calls (对外部调用也一样)\n\u0026gt; 3. 业务逻辑总是考虑退出机制，编码时避免潜在的死循环\n\u0026gt; 4. 在合适的地方插入响应 channel 的代码，保持一定频率的 channel 响应能力\n使用 context GO Context blog\nGO Context pkg\n对上面两篇文章的整理翻译。\ncontext 对一个 Go 服务，处理传入请求时应该创建一个Context，外部调用时应该接受一个Context。它们间的函数调用链必须传递Context，传递的 Context 也可以是使用WithCancel, WithDeadline, WithTimeout, or WithValue创建的继承来的Context。当一个Context被取消，所有继承它的Context也都会取消。\n// A Context carries a deadline, cancelation signal, and request-scoped values // across API boundaries. Its methods are safe for simultaneous use by multiple // goroutines. type Context interface { // Done returns a channel that is closed when this Context is canceled // or times out. Done() \u0026lt;-chan struct{} // Err indicates why this context was canceled, after the Done channel // is closed. Err() error // Deadline returns the time when this Context will be canceled, if any. Deadline() (deadline time.Time, ok bool) // Value returns the value associated with key or nil if none. Value(key interface{}) interface{} }   Done 返回一个只读信道（channel），它是表示 Context 是否已关闭(cancel)的信号。\n Err 返回Context被关闭的原因。\n Deadline 让方法可以决定是否应该开始工作，如果剩下的时间太少，可能不需要运行。也可以使用 deadline 来设置IO操作的超时时间。\n Value 方法允许Context绑定一个请求范围内(request-scoped)的数据。这个数据一定是线程安全的。\n  Context没有 cancel 方法和Done 信道是只读的原因一样：接收关闭信号(signal)的方法(function)通常不是发送信号的方法，尤其是，当父操作为子操作启动 goroutine 时，这些子操作的 goroutine 不应该能够关闭父操作。相反，WithCancel方法提供了关闭新Context的方式。\n多个 goroutine 同时使用一个Context是安全的。代码可以将单个Context传递给任意数量的 goroutine，并关闭该Conetxt以向所有这些 goroutine 发出信号。\nDerived contexts context包提供了从现有Context中继承新的Context的方法。这些Context构成一个树：当一个Context被关闭(cancel)时，继承自它的所有Context都会被关闭。\nBackground 是所有 Context 树的根，它永远不会关闭(cancel)：\n// Background returns an empty Context. It is never canceled, has no deadline, // and has no values. Background is typically used in main, init, and tests, // and as the top-level Context for incoming requests. func Background() Context  WithCancel和WithTimeout返回派生的Context，这些值可以比父Context更早取消。通常在请求处理程序返回时关闭与传入请求相关联的Context。WithCancel对于在使用多个副本时关闭冗余请求很有用。WithTimeout对设置后端服务器请求的截止日期时很有用：\n/ WithCancel returns a copy of parent whose Done channel is closed as soon as // parent.Done is closed or cancel is called. func WithCancel(parent Context) (ctx Context, cancel CancelFunc) // A CancelFunc cancels a Context. type CancelFunc func() // WithTimeout returns a copy of parent whose Done channel is closed as soon as // parent.Done is closed, cancel is called, or timeout elapses. The new // Context's Deadline is the sooner of now+timeout and the parent's deadline, if // any. If the timer is still running, the cancel function releases its // resources. func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)  WithValue提供了一种将请求范围的值与Context绑定的方法：\n// WithValue returns a copy of parent whose Value method returns val for key. func WithValue(parent Context, key interface{}, val interface{}) Context  使用原则 Programs that use Contexts should follow these rules to keep interfaces consistent across packages and enable static analysis tools to check context propagation:\n使用Context的程序包需要遵循如下的原则来满足接口的一致性以及便于静态分析。\n- Do not store Contexts inside a struct type; instead, pass a Context explicitly to each function that needs it. The Context should be the first parameter, typically named ctx;\n不要把 Context 存在一个结构体当中，显式地传入函数。Context变量需要作为第一个参数使用，一般命名为ctx；\n- Do not pass a nil Context, even if a function permits it. Pass context.TODO if you are unsure about which Context to use;\n即使方法允许，也不要传入一个 nil 的 Context，如果你不确定你要用什么 Context 的时候传一个 context.TODO；\n- Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions;\n使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数；\n- The same Context may be passed to functions running in different goroutines; Contexts are safe for simultaneous use by multiple goroutines.\n同样的Context可以用来传递到不同的goroutine中，Context在多个goroutine中是安全的。\n"
},
{
	"uri": "/cloud/apiserver/",
	"title": "Apiserver",
	"tags": [],
	"description": "",
	"content": "k8s apiserver 源码阅读笔记\n代码结构 本部分用于记录 apiserver 代码整体结构及关键方法，便于到源码中查找，个人阅读记录，读者可跳过。本文所有代码均基于 kubernetes 1.9.6。  app.Run() CreateServerChain() CreateNodeDialer()\t//ssh 连接 CreateKubeAPIServerConfig()\t// defaultOptions() DefaultAdvertiseAddress() DefaultServiceIPRange() MaybeDefaultWithSelfSignedCerts() ApplyAuthorization() IsValidServiceAccountKeyFile() Validate() //validate options BuildGenericConfig()\t//takes the master server options and produces the genericapiserver.Config associated with it genericConfig genericConfig.OpenAPIConfig //config swagger BuildStorageFactory()\t//constructs the storage factory func NewStorageFactory(storageConfig storagebackend.Config, defaultMediaType string, serializer runtime.StorageSerializer, defaultResourceEncoding *serverstorage.DefaultResourceEncodingConfig, storageEncodingOverrides map[string]schema.GroupVersion, resourceEncodingOverrides []schema.GroupVersionResource, defaultAPIResourceConfig *serverstorage.ResourceConfig, resourceConfigOverrides utilflag.ConfigurationMap) (*serverstorage.DefaultStorageFactory, error) // storageConfig -\u0026gt; ETCD配置 // defaultAPIResourceConfig -\u0026gt; func DefaultAPIResourceConfigSource() *serverstorage.ResourceConfig type ResourceConfig struct { GroupVersionResourceConfigs map[schema.GroupVersion]*GroupVersionResourceConfig } func (o *ResourceConfig) EnableVersions(versions ...schema.GroupVersion)\t//Enable GroupVersion func (o *ResourceConfig) EnableResources(resources ...schema.GroupVersionResource) //daemonsets,deployments,ingresses,networkpolicies,replicasets,podsecuritypolicies // Specifies the overrides for various API group versions. // This can be used to enable/disable entire group versions or specific resources. type GroupVersionResourceConfig struct { // Whether to enable or disable this entire group version. This dominates any enablement check. // Enable=true means the group version is enabled, and EnabledResources/DisabledResources are considered. // Enable=false means the group version is disabled, and EnabledResources/DisabledResources are not considered. Enable bool // DisabledResources lists the resources that are specifically disabled for a group/version // DisabledResources trumps EnabledResources DisabledResources sets.String // EnabledResources lists the resources that should be enabled by default. This is a little // unusual, but we need it for compatibility with old code for now. An empty set means // enable all, a non-empty set means that all other resources are disabled. EnabledResources sets.String } EtcdServersOverrides //override etcd配置 client, err := internalclientset.NewForConfig(genericConfig.LoopbackClientConfig) // new a loopback client sharedInformers := informers.NewSharedInformerFactory(client, 10*time.Minute)\t// SharedInformerFactory provides shared informers for resources in all known API group versions. type SharedInformerFactory interface { internalinterfaces.SharedInformerFactory ForResource(resource schema.GroupVersionResource) (GenericInformer, error) WaitForCacheSync(stopCh \u0026lt;-chan struct{}) map[reflect.Type]bool Admissionregistration() admissionregistration.Interface Apps() apps.Interface Autoscaling() autoscaling.Interface Batch() batch.Interface Certificates() certificates.Interface Core() core.Interface Extensions() extensions.Interface Networking() networking.Interface Policy() policy.Interface Rbac() rbac.Interface Scheduling() scheduling.Interface Settings() settings.Interface Storage() storage.Interface } serviceResolver // A ServiceResolver knows how to get a URL given a service. type ServiceResolver interface { ResolveEndpoint(namespace, name string) (*url.URL, error) } DefaultServiceIPRange() BuildStorageFactory() readCAorNil()\t//auth CA config := \u0026amp;master.Config{} type Config struct { GenericConfig *genericapiserver.Config ExtraConfig ExtraConfig } createAPIExtensionsConfig() createAPIExtensionsServer() // apiextensions-apiserver\\pkg\\apiserver\\apiserver.go New() is the function for CustomResourceDefinitions to register router handler on GenericAPIServer CreateKubeAPIServer() // creates and wires a workable kube-apiserver, // returns a new instance of Master from the given config func (c completedConfig) New(delegationTarget genericapiserver.DelegationTarget) (*Master, error){} // goproject\\src\\k8s.io\\kubernetes\\pkg\\master\\master.go c.GenericConfig.New(\u0026quot;kube-apiserver\u0026quot;, delegationTarget)\t// creates a new server which logically combines the handling chain with the passed server !! important apiServerHandler := NewAPIServerHandler(name, c.RequestContextMapper, c.Serializer, handlerChainBuilder, delegationTarget.UnprotectedHandler()) // k8s.io\\apiserver\\pkg\\server\\handler.go construct gorestfulContainer and add default handler(NotFoundHandler, RecoverHandler, ServiceErrorHandler) func NewAPIServerHandler(name string, contextMapper request.RequestContextMapper, s runtime.NegotiatedSerializer, handlerChainBuilder HandlerChainBuilderFn, notFoundHandler http.Handler) *APIServerHandler {} director := director{...} type director struct { name string goRestfulContainer *restful.Container nonGoRestfulMux *mux.PathRecorderMux } func (d director) ServeHTTP(w http.ResponseWriter, req *http.Request) {} s := \u0026amp;GenericAPIServer{}\t// k8s.io\\apiserver\\pkg\\server\\genericapiserver.go type GenericAPIServer add PostStartHooks \u0026amp; PreShutdownHooks AddPostStartHook(PostStartHookFunc)\t//\t{c.SharedInformerFactory.Start(context.StopCh)} add healthzChecks installAPI(s, c.Config)\t// install utils routes like SwaggerUI, Profiling, Metrics if () routes.DefaultMetrics{}.Install(s.Handler.NonGoRestfulMux) if () routes.Logs{}.Install(s.Handler.GoRestfulContainer) m := \u0026amp;Master{ GenericAPIServer: s, } m.InstallLegacyAPI(\u0026amp;c, c.GenericConfig.RESTOptionsGetter, legacyRESTStorageProvider)\t// k8s.io\\kubernetes\\pkg\\master\\master.go, install core api routes, !!!!important NewLegacyRESTStorage() -\u0026gt; //定义如下 返回 LegacyRESTStorage和APIGroupInfo, Storage保存了具体资源对象的结构，如 PodStrorage // LegacyRESTStorage returns stateful information about particular instances of REST storage to master.go for wiring controllers func (c LegacyRESTStorageProvider) NewLegacyRESTStorage(restOptionsGetter generic.RESTOptionsGetter) (LegacyRESTStorage, genericapiserver.APIGroupInfo, error) {} // k8s.io\\kubernetes\\pkg\\registry\\core\\rest\\storage_core.go // Info about an API group. type APIGroupInfo struct { GroupMeta apimachinery.GroupMeta // Info about the resources in this group. Its a map from version to resource to the storage. VersionedResourcesStorageMap map[string]map[string]rest.Storage\t// !!! important!!!! // OptionsExternalVersion controls the APIVersion used for common objects in the // schema like api.Status, api.DeleteOptions, and metav1.ListOptions. Other implementors may // define a version \u0026quot;v1beta1\u0026quot; but want to use the Kubernetes \u0026quot;v1\u0026quot; internal objects. // If nil, defaults to groupMeta.GroupVersion. // TODO: Remove this when https://github.com/kubernetes/kubernetes/issues/19018 is fixed. OptionsExternalVersion *schema.GroupVersion // MetaGroupVersion defaults to \u0026quot;meta.k8s.io/v1\u0026quot; and is the scheme group version used to decode // common API implementations like ListOptions. Future changes will allow this to vary by group // version (for when the inevitable meta/v2 group emerges). MetaGroupVersion *schema.GroupVersion // Scheme includes all of the types used by this group and how to convert between them (or // to convert objects from outside of this group that are accepted in this API). // TODO: replace with interfaces Scheme *runtime.Scheme // NegotiatedSerializer controls how this group encodes and decodes data NegotiatedSerializer runtime.NegotiatedSerializer // ParameterCodec performs conversions for query parameters passed to API calls ParameterCodec runtime.ParameterCodec } restStorage := LegacyRESTStorage{} // NewREST for basic resources podTemplateStorage := podtemplatestore.NewREST(restOptionsGetter) eventStorage := eventstore.NewREST(restOptionsGetter, uint64(c.EventTTL.Seconds())) limitRangeStorage := limitrangestore.NewREST(restOptionsGetter) resourceQuotaStorage, resourceQuotaStatusStorage := resourcequotastore.NewREST(restOptionsGetter) secretStorage := secretstore.NewREST(restOptionsGetter) serviceAccountStorage := serviceaccountstore.NewREST(restOptionsGetter) persistentVolumeStorage, persistentVolumeStatusStorage := pvstore.NewREST(restOptionsGetter) persistentVolumeClaimStorage, persistentVolumeClaimStatusStorage := pvcstore.NewREST(restOptionsGetter) configMapStorage := configmapstore.NewREST(restOptionsGetter) namespaceStorage, namespaceStatusStorage, namespaceFinalizeStorage := namespacestore.NewREST(restOptionsGetter) endpointsStorage := endpointsstore.NewREST(restOptionsGetter) endpointRegistry := endpoint.NewRegistry(endpointsStorage) podStorage := podstore.NewStorage() serviceRESTStorage, serviceStatusStorage := servicestore.NewREST(restOptionsGetter) serviceRegistry := service.NewRegistry(serviceRESTStorage) restStorageMap := map[string]rest.Storage{ \u0026quot;pods\u0026quot;: podStorage.Pod, \u0026quot;pods/attach\u0026quot;: podStorage.Attach, // ............... \u0026quot;configMaps\u0026quot;: configMapStorage, \u0026quot;componentStatuses\u0026quot;: componentstatus.NewStorage(componentStatusStorage{c.StorageFactory}.serversToValidate), } apiGroupInfo.VersionedResourcesStorageMap[\u0026quot;v1\u0026quot;] = restStorageMap // set APIGroupInfo.VersionedResourcesStorageMap to return, !!!!! // construct BootstrapController and add hook NewBootstrapController()\t// a controller for watching the core capabilities of the master AddPostStartHookOrDie() // { controller.start() } AddPreShutdownHookOrDie() // { controller.stop() } InstallLegacyAPIGroup() func (s *GenericAPIServer) InstallLegacyAPIGroup(apiPrefix string, apiGroupInfo *APIGroupInfo) error {} if legacyAPIGroupPrefixes.Has(apiPrefix) installAPIResources()\t// a private method for installing the REST storage backing each api groupversionresource for apiGroupInfo.GroupMeta.GroupVersions { // get rest.Storage from apiGroupInfo.VersionedResourcesStorageMap[groupVersion.Version] apiGroupVersion := s.getAPIGroupVersion(apiGroupInfo, groupVersion, apiPrefix) // InstallREST registers the REST handlers (storage, watch, proxy and redirect) into a restful Container apiGroupVersion.InstallREST(s.Handler.GoRestfulContainer) installer := \u0026amp;APIInstaller{ group: g,...} installer.Install() // Install handlers for API resources. k8s.io\\apiserver\\pkg\\endpoints\\installer.go func (a *APIInstaller) Install() ([]metav1.APIResource, *restful.WebService, []error) {} paths := make([]string, len(a.group.Storage)) for paths(storages) { apiResource, err := a.registerResourceHandlers(path, a.group.Storage[path], ws, proxyHandler)\t// !!important(700+ lines...), function to actually add route to go-restful. k8s.io\\apiserver\\pkg\\endpoints\\installer.go // kubernetes把所有对资源对象的操作接口封装到一个action对象中，在 registerResourceHandlers 方法中， // 根据如 storage.(rest.Getter)的方法，获取 what verbs are supported by the storage, used to know what verbs we support per path， // 根据scope: RESTScopeNameRoot(Handle non-namespace scoped resources like nodes) 或 RESTScopeNameNamespace(Handler for standard REST verbs (GET, PUT, POST and DELETE)) // 将 action append 到一个 actions 切片中(不同 scope ，path前缀不同) // 最后遍历actions，根据不同的action.Verb，注册到go-restful的 restful.WebService中，并将此对象支持的Verbs将入到apiResource.Verbs中并返回apiResource对象。 func (a *APIInstaller) registerResourceHandlers(path string, storage rest.Storage, ws *restful.WebService, proxyHandler http.Handler) (*metav1.APIResource, error) {} // Struct capturing information about an action (\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;, \u0026quot;WATCH\u0026quot;, \u0026quot;PROXY\u0026quot;, etc). type action struct { Verb string // Verb identifying the action (\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;, \u0026quot;WATCH\u0026quot;, \u0026quot;PROXY\u0026quot;, etc). Path string // The path of the action Params []*restful.Parameter // List of parameters associated with the action. Namer handlers.ScopeNamer AllNamespaces bool // true iff the action is namespaced but works on aggregate result for all namespaces } // APIResource specifies the name of a resource and whether it is namespaced. type APIResource struct { // name is the plural name of the resource. Name string `json:\u0026quot;name\u0026quot; protobuf:\u0026quot;bytes,1,opt,name=name\u0026quot;` // singularName is the singular name of the resource. This allows clients to handle plural and singular opaquely. // The singularName is more correct for reporting status on a single item and both singular and plural are allowed // from the kubectl CLI interface. SingularName string `json:\u0026quot;singularName\u0026quot; protobuf:\u0026quot;bytes,6,opt,name=singularName\u0026quot;` // namespaced indicates if a resource is namespaced or not. Namespaced bool `json:\u0026quot;namespaced\u0026quot; protobuf:\u0026quot;varint,2,opt,name=namespaced\u0026quot;` // group is the preferred group of the resource. Empty implies the group of the containing resource list. // For subresources, this may have a different value, for example: Scale\u0026quot;. Group string `json:\u0026quot;group,omitempty\u0026quot; protobuf:\u0026quot;bytes,8,opt,name=group\u0026quot;` // version is the preferred version of the resource. Empty implies the version of the containing resource list // For subresources, this may have a different value, for example: v1 (while inside a v1beta1 version of the core resource's group)\u0026quot;. Version string `json:\u0026quot;version,omitempty\u0026quot; protobuf:\u0026quot;bytes,9,opt,name=version\u0026quot;` // kind is the kind for the resource (e.g. 'Foo' is the kind for a resource 'foo') Kind string `json:\u0026quot;kind\u0026quot; protobuf:\u0026quot;bytes,3,opt,name=kind\u0026quot;` // verbs is a list of supported kube verbs (this includes get, list, watch, create, // update, patch, delete, deletecollection, and proxy) Verbs Verbs `json:\u0026quot;verbs\u0026quot; protobuf:\u0026quot;bytes,4,opt,name=verbs\u0026quot;` // shortNames is a list of suggested short names of the resource. ShortNames []string `json:\u0026quot;shortNames,omitempty\u0026quot; protobuf:\u0026quot;bytes,5,rep,name=shortNames\u0026quot;` // categories is a list of the grouped resources this resource belongs to (e.g. 'all') Categories []string `json:\u0026quot;categories,omitempty\u0026quot; protobuf:\u0026quot;bytes,7,rep,name=categories\u0026quot;` } apiResources = append(apiResources, *apiResource) } } m.InstallAPIs(c.ExtraConfig.APIResourceConfigSource, c.GenericConfig.RESTOptionsGetter, restStorageProviders...)\t// InstallAPIs will install the APIs for the restStorageProviders if they are enabled. for restStorageProviders { apiGroupsInfo = append(apiGroupsInfo, apiGroupInfo) } for i := range apiGroupsInfo { m.GenericAPIServer.InstallAPIGroup(\u0026amp;apiGroupsInfo[i]) // installAPIResources is a private method for installing the REST storage backing each api groupversionresource, k8s.io\\apiserver\\pkg\\server\\genericapiserver.go func (s *GenericAPIServer) installAPIResources(apiPrefix string, apiGroupInfo *APIGroupInfo) error {} // ！！InstallREST registers the REST handlers (storage, watch, proxy and redirect) into a restful Container, k8s.io\\apiserver\\pkg\\endpoints\\groupversion.go apiGroupVersion.InstallREST(s.Handler.GoRestfulContainer } m.installTunneler(c.ExtraConfig.Tunneler, corev1client.NewForConfigOrDie(c.GenericConfig.LoopbackClientConfig).Nodes()) m.GenericAPIServer.AddPostStartHookOrDie(\u0026quot;ca-registration\u0026quot;, c.ExtraConfig.ClientCARegistrationHook.PostStartHook) AddPostStartHook()\t// addfunc {sharedInformers.Start(context.StopCh)} // openapi swagger // this wires up openapi kubeAPIServer.GenericAPIServer.PrepareRun() // This will wire up openapi for extension api server apiExtensionsServer.GenericAPIServer.PrepareRun() aggregatorConfig, err := createAggregatorConfig(*kubeAPIServerConfig.GenericConfig, runOptions, versionedInformers, serviceResolver, proxyTransport) aggregatorServer, err := createAggregatorServer(aggregatorConfig, kubeAPIServer.GenericAPIServer, apiExtensionsServer.Informers) aggregatorServer, err := aggregatorConfig.Complete().NewWithDelegate(delegateAPIServer) genericServer, err := c.GenericConfig.New(\u0026quot;kube-aggregator\u0026quot;, delegationTarget) // ----same function with called in CreateKubeAPIServer-\u0026gt;New() (91) apiregistrationClient, err := internalclientset.NewForConfig(c.GenericConfig.LoopbackClientConfig) configShallowCopy.RateLimiter = flowcontrol.NewTokenBucketRateLimiter(configShallowCopy.QPS, configShallowCopy.Burst) cs.apiregistration, err = apiregistrationinternalversion.NewForConfig(\u0026amp;configShallowCopy) cs.DiscoveryClient, err = discovery.NewDiscoveryClientForConfig(\u0026amp;configShallowCopy) informerFactory := informers.NewSharedInformerFactory(apiregistrationClient,5*time.Minute,) s := \u0026amp;APIAggregator{}\t// APIAggregator contains state for a Kubernetes cluster master/api server. v1beta1storage := map[string]rest.Storage{} apiServiceREST := apiservicestorage.NewREST(Scheme, c.GenericConfig.RESTOptionsGetter) v1beta1storage[\u0026quot;apiservices\u0026quot;] = apiServiceREST v1beta1storage[\u0026quot;apiservices/status\u0026quot;] = apiservicestorage.NewStatusREST(Scheme, apiServiceREST) // rest implements a RESTStorage for API services against etcd type REST struct { *genericregistry.Store } apiGroupInfo.VersionedResourcesStorageMap[\u0026quot;v1beta1\u0026quot;] = v1beta1storage s.GenericAPIServer.InstallAPIGroup(\u0026amp;apiGroupInfo)\t// ----same function with called in CreateKubeAPIServer-\u0026gt;New()-\u0026gt;InstallAPIs() (237) s.GenericAPIServer.Handler.NonGoRestfulMux.Handle(\u0026quot;/apis\u0026quot;, apisHandler) s.GenericAPIServer.Handler.NonGoRestfulMux.UnlistedHandle(\u0026quot;/apis/\u0026quot;, apisHandler) apiserviceRegistrationController := NewAPIServiceRegistrationController(informerFactory.Apiregistration().InternalVersion().APIServices(), c.GenericConfig.SharedInformerFactory.Core().V1().Services(), s) // add event handler to informer s.GenericAPIServer.AddPostStartHook(\u0026quot;start-kube-aggregator-informers\u0026quot;) s.GenericAPIServer.AddPostStartHook(\u0026quot;apiservice-registration-controller\u0026quot;) s.GenericAPIServer.AddPostStartHook(\u0026quot;apiservice-status-available-controller\u0026quot;) // BuildAndRegisterAggregator registered OpenAPI aggregator handler. openAPIAggregator, err := openapicontroller.BuildAndRegisterAggregator() // create controllers for auto-registration apiRegistrationClient, err := apiregistrationclient.NewForConfig(aggregatorConfig.GenericConfig.LoopbackClientConfig) // ......  app.Run kubernetes所有组件的入口，基本上都是在$GOPATH\\k8s.io\\kubernetes\\cmd\\xxx(组件名称)下面的main文件中。 apiserver对应的路径为$GOPATH\\k8s.io\\kubernetes\\cmd\\kube-apiserver\\apiserver.go，main函数中通过app.Run(s, stopCh)方法，执行具体逻辑。 具体Run方法，定义在$GOPATH\\k8s.io\\kubernetes\\cmd\\kube-apiserver\\app\\server.go中。\napiserver的app.Run()，主要通过 CreateServerChain() 方法，创建出一个*genericapiserver.GenericAPIServer实例。\n在GenericAPIServer中，包含的主要结构体有\n- *APIServerHandler(Handler holds the handlers being used by this API server) - DelegationTarget(delegationTarget is the next delegate in the chain or nil)\n其中最重要的是APIServerHandler这个结构体，它包含了go-restful中的*restful.Container结构体，后面注册API时用到的InstallAPIs()方法，最终也是将路由注册到这个Container中，定义如下:\n// APIServerHandlers holds the different http.Handlers used by the API server. // This includes the full handler chain, the director (which chooses between gorestful and nonGoRestful, // the gorestful handler (used for the API) which falls through to the nonGoRestful handler on unregistered paths, // and the nonGoRestful handler (which can contain a fallthrough of its own) // FullHandlerChain -\u0026gt; Director -\u0026gt; {GoRestfulContainer,NonGoRestfulMux} based on inspection of registered web services type APIServerHandler struct { // FullHandlerChain is the one that is eventually served with. It should include the full filter // chain and then call the Director. FullHandlerChain http.Handler // The registered APIs. InstallAPIs uses this. Other servers probably shouldn't access this directly. GoRestfulContainer *restful.Container // NonGoRestfulMux is the final HTTP handler in the chain. // It comes after all filters and the API handling // This is where other servers can attach handler to various parts of the chain. NonGoRestfulMux *mux.PathRecorderMux // Other servers should only use this opaquely to delegate to an API server. Director http.Handler }  DelegationTarget(DelegationTarget is an interface which allows for composition of API servers with top level handling that works as expected.)是一个interface，是构成方法名CreateServerChain中ServerChain的结构，结构体内定义了NextDelegate()方法，返回chain中的下一个DelegationTarget，由它串起了多个api servers。(为什么会有多个api server从后面代码中可以看到。)\nCreateServerChain // CreateServerChain creates the apiservers connected via delegation. func CreateServerChain(runOptions *options.ServerRunOptions, stopCh \u0026lt;-chan struct{}) (*genericapiserver.GenericAPIServer, error) {}  CreateServerChain()方法中，先后执行了CreateNodeDialer, CreateKubeAPIServerConfig, createAPIExtensionsConfig, createAPIExtensionsServer, CreateKubeAPIServer, createAggregatorConfig, createAggregatorServer几个方法，根据方法名可以看出启动apiserver的流程。\n CreateNodeDialer(CreateNodeDialer creates the dialer infrastructure to connect to the nodes), add SSH Key, 返回一个tunneler.Tunneler, 可以通过创建到node节点的SSH连接。\n CreateKubeAPIServerConfig(creates all the resources for running the API server, but runs none of them), 创建出所有apiserver所需的配置和资源，包括配置的Validate，命令行参数解析，openapi/swagger配置，StorageFactory,clientset, informer, serviceResolver 等资源的创建。\n createAPIExtensionsConfig, 传入由上一步生成的配置*kubeAPIServerConfig.GenericConfig和 informer, 通过apiextensionscmd.NewCRDRESTOptionsGetter(etcdOptions)初始化ExtraConfig.CRDRESTOptionsGetter并创建 apiextensionsConfig 返回。\n createAPIExtensionsServer, 通过上一步生成的apiExtensionsConfig，通过一个genericapiserver.EmptyDelegate创建 apiExtensionsServer。返回 apiserver 的是一个apiextensionsapiserver.CustomResourceDefinitions结构体。其中生成 CustomResourceDefinitions 结构体的 New() 方法，真正将 CRD 接口添加到apiGroupInfo.VersionedResourcesStorageMap中，并注册到 go-resetful 的 webService，同时会通过AddPostStartHook添加启动后hook，启动informer(事件监听)和crdController, namingController, finalizingController三个 Controler 监听 CRD Resource 的变化。\n CreateKubeAPIServer(creates and wires a workable kube-apiserver), 通过以上几步生成的 apiserver 配置，通过createAPIExtensionsServer生成的DelegationTarget创建 apiserver 实例(master.Master)。这个过程中会 install kubernetes 的 core api 并 启动 BootStrapController(a controller for watching the core capabilities of the master), install nodeTunneler 并添加ca-registration的 PostStartHook。\n createAggregatorConfig, 通过上面生成的 apiserver 配置生成 AggregatorConfig。(代码中只是浅拷贝一份kubeAPIServerConfig.GenericConfig并添加了 Proxy 相关的 ExtraConfig 到返回的*aggregatorapiserver.Config结构体中。)\n createAggregatorServer, 生成 AggregatorServer(*Aggregator for Kubernetes-style API servers: dynamic registration, discovery summarization, secure proxy *)。这个过程中，会启动apiserviceRegistrationController, availableController 去监听 api service 资源，完成 api service 的发现和注册。\n  这里解释一下 aggregator, 这是 kubernetes 为了增强 apiserver 的扩展性，方便用户开发自己的 api服务而开发的机制。它允许k8s的开发人员编写一个自己的服务，可以把这个服务注册到k8s的api里面，这样，就像k8s自己的api一样，你的服务只要运行在k8s集群里面，k8s 的Aggregate通过service名称就可以转发到你写的service里面去了。\n\u0026gt;Aggregated（聚合的）API server是为了将原来的API server这个巨石（monolithic）应用给拆分成，为了方便用户开发自己的API server集成进来，而不用直接修改kubernetes官方仓库的代码，这样一来也能将API server解耦，方便用户使用实验特性。这些API server可以跟core API server无缝衔接，使用kubectl也可以管理它们。\n到这里， apiserver的启动就基本完成了。\n下面主要分析下以上几个流程中CreateKubeAPIServerConfig和CreateKubeAPIServer两个方法，这也是创建出核心的apiserver 和真正执行k8s core api 注册的过程。\nCreateKubeAPIServerConfig kubeAPIServerConfig, sharedInformers, versionedInformers, insecureServingOptions, serviceResolver, err := CreateKubeAPIServerConfig(runOptions, nodeTunneler, proxyTransport) // CreateKubeAPIServerConfig creates all the resources for running the API server, but runs none of them func CreateKubeAPIServerConfig(s *options.ServerRunOptions, nodeTunneler tunneler.Tunneler, proxyTransport *http.Transport) (*master.Config, informers.SharedInformerFactory, clientgoinformers.SharedInformerFactory, *kubeserver.InsecureServingInfo, aggregatorapiserver.ServiceResolver, error) {}  方法的注释是 创建为了运行API server所需的所有资源，但是不会运行。就是说，这个方法负责创建后面启动的apiserver所需的所有配置及相关类的初始化。通过返回参数看，这些资源至少包括apiserver的配置, SharedInformerFactory(provides shared informers for resources in all known API group versions), InsecureServingInfo(is required to serve http. HTTP does NOT include authentication or authorization.), ServiceResolver(knows how to get a URL given a service)。\n主要流程 CreateKubeAPIServerConfig 首先是通过 defaultOptions 方法 在创建真正的 apiserver配置前将 options 中的参数以默认值补全，并对参数进行Validate, 然后通过BuildGenericConfig方法，根据 options 创建*genericapiserver.Config, 同时 SharedInformer和ServiceResolver都是在这个方法中创建的。 BuildGenericConfig方法中调用了很多ApplyTo方法，作用是将 options 中的各项配置参数解析到生成的config中, 在这个方法中还创建了[]admission.PluginInitializer。\n在这之后还有一个重要的方法是BuildStorageFactory，创建StorageFactory的时候需要传入 etcd 相关的配置。Storage是apiserver中一个很重要的概念，通过它执行对具体资源对象的操作，如对 POD 的 CRUD 等操作就是通过 PodStorage对象进行并连接到后端的 etcd 的。（同时 Storage 也是和 对应资源对象的 API 对应，后面installAPI的时候也是通过 Storage 来注册 API 路由的。）\n最后，配置默认的ServiceIPRange 和 获取 CA 证书等配置，将上面创建的配置注入一个\u0026amp;master.Config实例并返回。\nServiceResolver ServiceResolver的定义及创建方法如下，通过 SharedInformer 的 lister 方法监听 kubernetes Service 资源的变化，实现获取 Service 的 URL 的功能。\nserviceResolver = aggregatorapiserver.NewClusterIPServiceResolver( versionedInformers.Core().V1().Services().Lister(), ) // A ServiceResolver knows how to get a URL given a service. type ServiceResolver interface { ResolveEndpoint(namespace, name string) (*url.URL, error) }  SharedInformer CreateKubeAPIServerConfig 返回两个SharedInformerFactory, 实际上结构体的定义完全相同，区别是定义在不同的包内，informers.SharedInformerFactory定义在 kubernetes 内部的pkg下，而clientgoinformers.SharedInformerFactory定义在 client-go 中，因此创建的时候，前者是通过internalclientset创建出的clientset创建，而后者是通过client-go的clientset创建，用来创建两者的配置是完全相同的。(第一次阅读，比较疑惑为什么需要两个clientset。猜测是一个用来内部通信，一个是用来外部通信。后面有时间的话，会再具体研究下。)\nSharedInformerFactory定义如下：\n// SharedInformerFactory provides shared informers for resources in all known // API group versions. type SharedInformerFactory interface { internalinterfaces.SharedInformerFactory ForResource(resource schema.GroupVersionResource) (GenericInformer, error) WaitForCacheSync(stopCh \u0026lt;-chan struct{}) map[reflect.Type]bool Admissionregistration() admissionregistration.Interface Apps() apps.Interface Autoscaling() autoscaling.Interface Batch() batch.Interface Certificates() certificates.Interface Core() core.Interface Extensions() extensions.Interface Networking() networking.Interface Policy() policy.Interface Rbac() rbac.Interface Scheduling() scheduling.Interface Settings() settings.Interface Storage() storage.Interface }  SharedInformerFactory为所有API group versions提供shared informers, shared informer又是什么呢？定义如下：\n// SharedInformer has a shared data cache and is capable of distributing notifications for changes // to the cache to multiple listeners who registered via AddEventHandler. If you use this, there is // one behavior change compared to a standard Informer. When you receive a notification, the cache // will be AT LEAST as fresh as the notification, but it MAY be more fresh. You should NOT depend // on the contents of the cache exactly matching the notification you've received in handler // functions. If there was a create, followed by a delete, the cache may NOT have your item. This // has advantages over the broadcaster since it allows us to share a common cache across many // controllers. Extending the broadcaster would have required us keep duplicate caches for each // watch. type SharedInformer interface { // AddEventHandler adds an event handler to the shared informer using the shared informer's resync // period. Events to a single handler are delivered sequentially, but there is no coordination // between different handlers. AddEventHandler(handler ResourceEventHandler) // AddEventHandlerWithResyncPeriod adds an event handler to the shared informer using the // specified resync period. Events to a single handler are delivered sequentially, but there is // no coordination between different handlers. AddEventHandlerWithResyncPeriod(handler ResourceEventHandler, resyncPeriod time.Duration) // GetStore returns the Store. GetStore() Store // GetController gives back a synthetic interface that \u0026quot;votes\u0026quot; to start the informer GetController() Controller // Run starts the shared informer, which will be stopped when stopCh is closed. Run(stopCh \u0026lt;-chan struct{}) // HasSynced returns true if the shared informer's store has synced. HasSynced() bool // LastSyncResourceVersion is the resource version observed when last synced with the underlying // store. The value returned is not synchronized with access to the underlying store and is not // thread-safe. LastSyncResourceVersion() string }  可以通过先两篇文章了解下SharedInformer, https://blog.csdn.net/weixin_42663840/article/details/81699303\nhttps://www.kubernetes.org.cn/2693.html\n简单来说，SharedInformer 有一个共享数据的cache, 并能够将 cache 的变化分发给多个 listener, 这些 listener 都是通过 AddEventHandler 方法注册到 SharedInformer。Informer 在初始化的时，先调用 Kubernetes List API 到 ETCD获得某种 resource 的全部 Object，缓存在内存中; 然后，调用 Watch API 去 watch 这种 resource，去维护这份缓存; 最后，Informer 就不再调用 Kubernetes 的任何 API。\nCreateKubeAPIServer kubeAPIServer, err := CreateKubeAPIServer(kubeAPIServerConfig, apiExtensionsServer.GenericAPIServer, sharedInformers, versionedInformers) // CreateKubeAPIServer creates and wires a workable kube-apiserver func CreateKubeAPIServer(kubeAPIServerConfig *master.Config, delegateAPIServer genericapiserver.DelegationTarget, sharedInformers informers.SharedInformerFactory, versionedInformers clientgoinformers.SharedInformerFactory) (*master.Master, error) {}  方法的注释 创建并装配一个可工作的 kube-apiserver, 到这里，一个真正可运行的apiserver实例就创建完成了。可以看到返回的 APIServer 类型是*master.Master，传入的就是之前CreateKubeAPIServer返回的配置和资源，加上delegateAPIServer。这是kubernetes组合多个 apiserver 的机制。\n主要流程 生成 kubeAPIServer 的是kubeAPIServerConfig.Complete(versionedInformers).New(delegateAPIServer)方法。在这个方法中，又调用了c.GenericConfig.New(\u0026quot;kube-apiserver\u0026quot;, delegationTarget)创建一个APIServer，并生成 Handler chain 和传入的delegateAPIServer组合起来；接着会新建*master.Master实例 m，并将c.GenericConfig.New 返回的 APIServer 赋值给 m.GenericAPIServer, 这个m也是CreateKubeAPIServer方法最终要返回的 APISever 实例。最后要做的就是执行m.InstallLegacyAPI, m.InstallAPIs注册 API 接口，添加 PostStartHook 然后将m返回。\nc.GenericConfig.New // New creates a new server which logically combines the handling chain with the passed server. // name is used to differentiate for logging. func (c completedConfig) New(name string, delegationTarget DelegationTarget) (*GenericAPIServer, error) {}  首先通过apiServerHandler := NewAPIServerHandler(name, c.RequestContextMapper, c.Serializer, handlerChainBuilder, delegationTarget.UnprotectedHandler())创建出一个APIServerHandler实例，结构体定义上面已经贴过了。\nNewAPIServerHandler 方法中，创建了nonGoRestfulMux和gorestfulContainer, 并给gorestfulContainer添加了几个默认Handler(NotFoundHandler, RecoverHandler, ServiceErrorHandler), 再这两者注入到一个 director 实例中，director 有一个 ServeHTTP, 用来最终启动 http 服务, 最后将director 赋值给 APIServerHandler.Director, 通过调用c.BuildHandlerChainFunc(director, c.Config)装饰director并赋值给APIServerHandler.FullHandlerChain最后返回。\n接着创建一个GenericAPIServer实例s，并将 NewAPIServerHandler 方法中返回的apiServerHandler赋值给s.Handler和s.listedPathProvider, 将传入的delegationTarget(即delegated apiserver) 中配置的 Hooks 和 HealthzCheckers 传递s, 并合并s和delegationTarget的 listedPathProvider(an interface for providing paths that should be reported at /), 最后执行installAPI(s, c.Config)安装 API 并返回s。\ndirector 如下是BuildHandlerChainFunc和*master.Config中默认的方法，可以看到是不断追加 handler 方法到 Handler 中。\n// BuildHandlerChainFunc allows you to build custom handler chains by decorating the apiHandler. BuildHandlerChainFunc func(apiHandler http.Handler, c *Config) (secure http.Handler) // default BuildHandlerChainFunc func DefaultBuildHandlerChain(apiHandler http.Handler, c *Config) http.Handler { handler := genericapifilters.WithAuthorization(apiHandler, c.RequestContextMapper, c.Authorizer, c.Serializer) handler = genericfilters.WithMaxInFlightLimit(handler, c.MaxRequestsInFlight, c.MaxMutatingRequestsInFlight, c.RequestContextMapper, c.LongRunningFunc) handler = genericapifilters.WithImpersonation(handler, c.RequestContextMapper, c.Authorizer, c.Serializer) if utilfeature.DefaultFeatureGate.Enabled(features.AdvancedAuditing) { handler = genericapifilters.WithAudit(handler, c.RequestContextMapper, c.AuditBackend, c.AuditPolicyChecker, c.LongRunningFunc) } else { handler = genericapifilters.WithLegacyAudit(handler, c.RequestContextMapper, c.LegacyAuditWriter) } failedHandler := genericapifilters.Unauthorized(c.RequestContextMapper, c.Serializer, c.SupportsBasicAuth) if utilfeature.DefaultFeatureGate.Enabled(features.AdvancedAuditing) { failedHandler = genericapifilters.WithFailedAuthenticationAudit(failedHandler, c.RequestContextMapper, c.AuditBackend, c.AuditPolicyChecker) } handler = genericapifilters.WithAuthentication(handler, c.RequestContextMapper, c.Authenticator, failedHandler) handler = genericfilters.WithCORS(handler, c.CorsAllowedOriginList, nil, nil, nil, \u0026quot;true\u0026quot;) handler = genericfilters.WithTimeoutForNonLongRunningRequests(handler, c.RequestContextMapper, c.LongRunningFunc, c.RequestTimeout) handler = genericfilters.WithWaitGroup(handler, c.RequestContextMapper, c.LongRunningFunc, c.HandlerChainWaitGroup) handler = genericapifilters.WithRequestInfo(handler, c.RequestInfoResolver, c.RequestContextMapper) handler = apirequest.WithRequestContext(handler, c.RequestContextMapper) handler = genericfilters.WithPanicRecovery(handler) return handler }  如下是director的定义及ServeHTTP方法，先匹配 path 是否是gorestful中的路径，是的话通过goRestfulContainer.Dispatch(w, req)分发到对应 handler 处理请求，不匹配的话就通过nonGoRestfulMux分发处理。\ntype director struct { name string goRestfulContainer *restful.Container nonGoRestfulMux *mux.PathRecorderMux } func (d director) ServeHTTP(w http.ResponseWriter, req *http.Request) { path := req.URL.Path // check to see if our webservices want to claim this path for _, ws := range d.goRestfulContainer.RegisteredWebServices() { switch { case ws.RootPath() == \u0026quot;/apis\u0026quot;: // if we are exactly /apis or /apis/, then we need special handling in loop. // normally these are passed to the nonGoRestfulMux, but if discovery is enabled, it will go directly. // We can't rely on a prefix match since /apis matches everything (see the big comment on Director above) if path == \u0026quot;/apis\u0026quot; || path == \u0026quot;/apis/\u0026quot; { glog.V(5).Infof(\u0026quot;%v: %v %q satisfied by gorestful with webservice %v\u0026quot;, d.name, req.Method, path, ws.RootPath()) // don't use servemux here because gorestful servemuxes get messed up when removing webservices // TODO fix gorestful, remove TPRs, or stop using gorestful d.goRestfulContainer.Dispatch(w, req) return } case strings.HasPrefix(path, ws.RootPath()): // ensure an exact match or a path boundary match if len(path) == len(ws.RootPath()) || path[len(ws.RootPath())] == '/' { glog.V(5).Infof(\u0026quot;%v: %v %q satisfied by gorestful with webservice %v\u0026quot;, d.name, req.Method, path, ws.RootPath()) // don't use servemux here because gorestful servemuxes get messed up when removing webservices // TODO fix gorestful, remove TPRs, or stop using gorestful d.goRestfulContainer.Dispatch(w, req) return } } } // if we didn't find a match, then we just skip gorestful altogether glog.V(5).Infof(\u0026quot;%v: %v %q satisfied by nonGoRestful\u0026quot;, d.name, req.Method, path) d.nonGoRestfulMux.ServeHTTP(w, req) }  ListedPathProvider // ListedPathProvider is an interface for providing paths that should be reported at /. type ListedPathProvider interface { // ListedPaths is an alphabetically sorted list of paths to be reported at /. ListedPaths() []string }  installAPI 这里的 installAPI 方法如下，只根据配置安装了 Index, SwaggerUI, Profiling, Metrics 等 API 到 NonGoRestfulMux, Version(/version) 到 GoRestfulContainer, 核心的 API 还没有安装。\nm.InstallLegacyAPI m.InstallLegacyAPI(\u0026amp;c, c.GenericConfig.RESTOptionsGetter, legacyRESTStorageProvider) func (m *Master) InstallLegacyAPI(c *completedConfig, restOptionsGetter generic.RESTOptionsGetter, legacyRESTStorageProvider corerest.LegacyRESTStorageProvider) {}  用于注册/api下的 API, 即core api。首先调用legacyRESTStorageProvider.NewLegacyRESTStorage创建legacyRESTStorage, 如果配置中EnableCoreControllers为True的话，创建BootStrapController并在 m的 PostStartHook 和 dPostStartHook 中添加启动和停止。最后执行m.GenericAPIServer.InstallLegacyAPIGroup安装 LegacyAPIGroup。\nNewLegacyRESTStorage legacyRESTStorage, apiGroupInfo, err := legacyRESTStorageProvider.NewLegacyRESTStorage(restOptionsGetter) func (c LegacyRESTStorageProvider) NewLegacyRESTStorage(restOptionsGetter generic.RESTOptionsGetter) (LegacyRESTStorage, genericapiserver.APIGroupInfo, error) {}  这个方法返回两个结构体，LegacyRESTStorage和genericapiserver.APIGroupInfo, 其中最重要的是 APIGroupInfo。APIGroupInfo 中，有一个VersionedResourcesStorageMap, 是API 版本到 Storage 资源的 map 关系，保存了不同版本的所有 Storage。下面贴出了两个结构体的定义。 首先会初始化一个 APIGroupInfo 实例apiGroupInfo, 接着会调用不同 Storage 资源的NewREST方法创建 Storage, 如: eventStorage, configMapStorage, namespaceStorage, serviceRESTStorage, podStorage等。NewREST方法返回一个 REST 结构体, 而 REST 结构体中，保存了*genericregistry.Store, 这个 Store 结构体提供了对应资源的 CRUD 等操作的方法，所有对资源的操作通过 Store 来访问到后端的 ETCD。其中 pod, node 和 service 对应的操作比较多，涉及 Status 的存储和更新, 所以 Storage 创建过程也较为复杂。尤其是 pod, 不仅涉及到本身和状态的存储和更新，还涉及到日志 proxy 等操作，所以单独封装了一个 PodStorage 结构体，其中包含了多种不同的 Store, 例如涉及到日志的LogREST需要传入 KubeletConnectionInfo, 涉及到 proxy 的 ProxyREST 需要传入 ProxyTransport等，每种 Store 都提供了对应资源的操作方法，如获取日志，建立连接等。这部分代码在k8s.io\\kubernetes\\pkg\\registry\\core\\rest\\storage_core.go, 有关 Pod 和 Service 的 Storage 创建及不同 Storage 对应的方法可以看一下。\n最后，所有 Storage 创建完后，会构建一个restStorageMap(具体内容会在下面贴出)，这个 map 最后会赋给apiGroupInfo.VersionedResourcesStorageMap[\u0026quot;v1\u0026quot;], 即 core API v1版本的所有资源都可以在这个 map 资源中找到。\n// LegacyRESTStorage returns stateful information about particular instances of REST storage to // master.go for wiring controllers. // TODO remove this by running the controller as a poststarthook type LegacyRESTStorage struct { ServiceClusterIPAllocator rangeallocation.RangeRegistry ServiceNodePortAllocator rangeallocation.RangeRegistry } // Info about an API group. type APIGroupInfo struct { GroupMeta apimachinery.GroupMeta // Info about the resources in this group. Its a map from version to resource to the storage. VersionedResourcesStorageMap map[string]map[string]rest.Storage // OptionsExternalVersion controls the APIVersion used for common objects in the // schema like api.Status, api.DeleteOptions, and metav1.ListOptions. Other implementors may // define a version \u0026quot;v1beta1\u0026quot; but want to use the Kubernetes \u0026quot;v1\u0026quot; internal objects. // If nil, defaults to groupMeta.GroupVersion. // TODO: Remove this when https://github.com/kubernetes/kubernetes/issues/19018 is fixed. OptionsExternalVersion *schema.GroupVersion // MetaGroupVersion defaults to \u0026quot;meta.k8s.io/v1\u0026quot; and is the scheme group version used to decode // common API implementations like ListOptions. Future changes will allow this to vary by group // version (for when the inevitable meta/v2 group emerges). MetaGroupVersion *schema.GroupVersion // Scheme includes all of the types used by this group and how to convert between them (or // to convert objects from outside of this group that are accepted in this API). // TODO: replace with interfaces Scheme *runtime.Scheme // NegotiatedSerializer controls how this group encodes and decodes data NegotiatedSerializer runtime.NegotiatedSerializer // ParameterCodec performs conversions for query parameters passed to API calls ParameterCodec runtime.ParameterCodec }  // restStorageMap restStorageMap := map[string]rest.Storage{ \u0026quot;pods\u0026quot;: podStorage.Pod, \u0026quot;pods/attach\u0026quot;: podStorage.Attach, \u0026quot;pods/status\u0026quot;: podStorage.Status, \u0026quot;pods/log\u0026quot;: podStorage.Log, \u0026quot;pods/exec\u0026quot;: podStorage.Exec, \u0026quot;pods/portforward\u0026quot;: podStorage.PortForward, \u0026quot;pods/proxy\u0026quot;: podStorage.Proxy, \u0026quot;pods/binding\u0026quot;: podStorage.Binding, \u0026quot;bindings\u0026quot;: podStorage.Binding, \u0026quot;podTemplates\u0026quot;: podTemplateStorage, \u0026quot;replicationControllers\u0026quot;: controllerStorage.Controller, \u0026quot;replicationControllers/status\u0026quot;: controllerStorage.Status, \u0026quot;services\u0026quot;: serviceRest.Service, \u0026quot;services/proxy\u0026quot;: serviceRest.Proxy, \u0026quot;services/status\u0026quot;: serviceStatusStorage, \u0026quot;endpoints\u0026quot;: endpointsStorage, \u0026quot;nodes\u0026quot;: nodeStorage.Node, \u0026quot;nodes/status\u0026quot;: nodeStorage.Status, \u0026quot;nodes/proxy\u0026quot;: nodeStorage.Proxy, \u0026quot;events\u0026quot;: eventStorage, \u0026quot;limitRanges\u0026quot;: limitRangeStorage, \u0026quot;resourceQuotas\u0026quot;: resourceQuotaStorage, \u0026quot;resourceQuotas/status\u0026quot;: resourceQuotaStatusStorage, \u0026quot;namespaces\u0026quot;: namespaceStorage, \u0026quot;namespaces/status\u0026quot;: namespaceStatusStorage, \u0026quot;namespaces/finalize\u0026quot;: namespaceFinalizeStorage, \u0026quot;secrets\u0026quot;: secretStorage, \u0026quot;serviceAccounts\u0026quot;: serviceAccountStorage, \u0026quot;persistentVolumes\u0026quot;: persistentVolumeStorage, \u0026quot;persistentVolumes/status\u0026quot;: persistentVolumeStatusStorage, \u0026quot;persistentVolumeClaims\u0026quot;: persistentVolumeClaimStorage, \u0026quot;persistentVolumeClaims/status\u0026quot;: persistentVolumeClaimStatusStorage, \u0026quot;configMaps\u0026quot;: configMapStorage, \u0026quot;componentStatuses\u0026quot;: componentstatus.NewStorage(componentStatusStorage{c.StorageFactory}.serversToValidate), }  InstallLegacyAPIGroup m.GenericAPIServer.InstallLegacyAPIGroup(genericapiserver.DefaultLegacyAPIPrefix, \u0026amp;apiGroupInfo) func (s *GenericAPIServer) InstallLegacyAPIGroup(apiPrefix string, apiGroupInfo *APIGroupInfo) error { if !s.legacyAPIGroupPrefixes.Has(apiPrefix) { return fmt.Errorf(\u0026quot;%q is not in the allowed legacy API prefixes: %v\u0026quot;, apiPrefix, s.legacyAPIGroupPrefixes.List()) } if err := s.installAPIResources(apiPrefix, apiGroupInfo); err != nil { return err } // setup discovery apiVersions := []string{} for _, groupVersion := range apiGroupInfo.GroupMeta.GroupVersions { apiVersions = append(apiVersions, groupVersion.Version) } // Install the version handler. // Add a handler at /\u0026lt;apiPrefix\u0026gt; to enumerate the supported api versions. s.Handler.GoRestfulContainer.Add(discovery.NewLegacyRootAPIHandler(s.discoveryAddresses, s.Serializer, apiPrefix, apiVersions, s.requestContextMapper).WebService()) return nil }  整个方法如上，主要两步，首先调用 installAPIResources(is a private method for installing the REST storage backing each api groupversionresource) 安装 API。\ninstallAPIResources 会遍历apiGroupInfo下的所有 groupVersion, 然后通过s.getAPIGroupVersion得到该 version 下所有的 Storage, 即上面apiGroupInfo.VersionedResourcesStorageMap[groupVersion.Version] map 中所对应的所有 Storage。并通过InstallREST注册到 REST API 的 Handler 中。InstallREST方法如下，在 installer.Install()方法中, 以上面的restStorageMap的 key 为 path, 将所有 Storage 通过registerResourceHandlers(具体方法在 k8s.io\\apiserver\\pkg\\endpoints\\installer.go, 一个近700行的 swich-case 的方法，有兴趣可以看下。)方法注册到 gorestful 的 WebService Route中，并返回一个*metav1.APIResource对象，Install 方法会返回所有 Storage 的生成的 APIResources 和注册到的 WebService。\n接着获取 GroupVersions 中的所有版本并注册到 GoRestfulContainer 中(adds a service to return the supported api versions at the legacy /api), 返回可支持 API 版本。\n// InstallREST registers the REST handlers (storage, watch, proxy and redirect) into a restful Container. // It is expected that the provided path root prefix will serve all operations. Root MUST NOT end // in a slash. func (g *APIGroupVersion) InstallREST(container *restful.Container) error { prefix := path.Join(g.Root, g.GroupVersion.Group, g.GroupVersion.Version) installer := \u0026amp;APIInstaller{ group: g, prefix: prefix, minRequestTimeout: g.MinRequestTimeout, enableAPIResponseCompression: g.EnableAPIResponseCompression, } apiResources, ws, registrationErrors := installer.Install() versionDiscoveryHandler := discovery.NewAPIVersionHandler(g.Serializer, g.GroupVersion, staticLister{apiResources}, g.Context) versionDiscoveryHandler.AddToWebService(ws) container.Add(ws) return utilerrors.NewAggregate(registrationErrors) } // Install handlers for API resources. func (a *APIInstaller) Install() ([]metav1.APIResource, *restful.WebService, []error) { var apiResources []metav1.APIResource var errors []error ws := a.newWebService() proxyHandler := (\u0026amp;handlers.ProxyHandler{ Prefix: a.prefix + \u0026quot;/proxy/\u0026quot;, Storage: a.group.Storage, Serializer: a.group.Serializer, Mapper: a.group.Context, }) // Register the paths in a deterministic (sorted) order to get a deterministic swagger spec. paths := make([]string, len(a.group.Storage)) var i int = 0 for path := range a.group.Storage { paths[i] = path i++ } sort.Strings(paths) for _, path := range paths { apiResource, err := a.registerResourceHandlers(path, a.group.Storage[path], ws, proxyHandler) if err != nil { errors = append(errors, fmt.Errorf(\u0026quot;error in registering resource: %s, %v\u0026quot;, path, err)) } if apiResource != nil { apiResources = append(apiResources, *apiResource) } } return apiResources, ws, errors }  m.InstallAPIs m.InstallAPIs(c.ExtraConfig.APIResourceConfigSource, c.GenericConfig.RESTOptionsGetter, restStorageProviders...) // InstallAPIs will install the APIs for the restStorageProviders if they are enabled. func (m *Master) InstallAPIs(apiResourceConfigSource serverstorage.APIResourceConfigSource, restOptionsGetter generic.RESTOptionsGetter, restStorageProviders ...RESTStorageProvider) {}  用于注册/apis下的 API。在调用 InstallAPIs 之前，会创建/apis下 Storage 的 RESTStorageProvider, 该 interface 的定义及创建在下面代码片段1贴出。\n每个 RESTStorageProvider, 都会有一个NewRESTStorage方法来创建对应资源的 Storage。调用 InstallAPIs 方法时，会将 restStorageProviders 列表传入。 InstallAPIs 会遍历传入的 restStorageProviders 列表，并调用每个 restStorageProvider 的 NewRESTStorage。\nNewRESTStorage方法, 会新建一个 APIGroupInfo, 然后针对 enable 的 API 版本, 调用 VXXStorage 获取对应版本的 ResourcesStorageMap 并存入 apiGroupInfo.VersionedResourcesStorageMap[VXX]中。用来获取 ResourcesStorageMap 的方法，和上面 InstallLegacyAPIGroup.NewLegacyRESTStorage 方法中一样，也是 NewREST, 具体逻辑也基本相同，返回一个 REST 结构体提供对资源的 CRUD 等操作。\nNewRESTStorage方法最终返回的 apiGroupInfo, 会被放入一个 apiGroupsInfo 列表，最后会遍历这个列表并针对每一个 apiGroupInfo 执行 m.GenericAPIServer.InstallAPIGroup(\u0026amp;apiGroupsInfo[i]), 这部分逻辑和 InstallLegacyAPIGroup 一样，通过调用 installAPIResources 将 API 注册到 GoRestfulContainer 中，详细的可以对照上面的 InstallLegacyAPIGroup 的分析参考源码。\n// 代码片段 1 // RESTStorageProvider is a factory type for REST storage. type RESTStorageProvider interface { GroupName() string NewRESTStorage(apiResourceConfigSource serverstorage.APIResourceConfigSource, restOptionsGetter generic.RESTOptionsGetter) (genericapiserver.APIGroupInfo, bool) } // The order here is preserved in discovery. // If resources with identical names exist in more than one of these groups (e.g. \u0026quot;deployments.apps\u0026quot;\u0026quot; and \u0026quot;deployments.extensions\u0026quot;), // the order of this list determines which group an unqualified resource name (e.g. \u0026quot;deployments\u0026quot;) should prefer. // This priority order is used for local discovery, but it ends up aggregated in `k8s.io/kubernetes/cmd/kube-apiserver/app/aggregator.go // with specific priorities. // TODO: describe the priority all the way down in the RESTStorageProviders and plumb it back through the various discovery // handlers that we have. restStorageProviders := []RESTStorageProvider{ authenticationrest.RESTStorageProvider{Authenticator: c.GenericConfig.Authenticator}, authorizationrest.RESTStorageProvider{Authorizer: c.GenericConfig.Authorizer, RuleResolver: c.GenericConfig.RuleResolver}, autoscalingrest.RESTStorageProvider{}, batchrest.RESTStorageProvider{}, certificatesrest.RESTStorageProvider{}, extensionsrest.RESTStorageProvider{}, networkingrest.RESTStorageProvider{}, policyrest.RESTStorageProvider{}, rbacrest.RESTStorageProvider{Authorizer: c.GenericConfig.Authorizer}, schedulingrest.RESTStorageProvider{}, settingsrest.RESTStorageProvider{}, storagerest.RESTStorageProvider{}, // keep apps after extensions so legacy clients resolve the extensions versions of shared resource names. // See https://github.com/kubernetes/kubernetes/issues/42392 appsrest.RESTStorageProvider{}, admissionregistrationrest.RESTStorageProvider{}, eventsrest.RESTStorageProvider{TTL: c.ExtraConfig.EventTTL}, } "
},
{
	"uri": "/cloud/kubelet/",
	"title": "Kubelet",
	"tags": [],
	"description": "",
	"content": "Kubelet 源码阅读笔记\n"
},
{
	"uri": "/cloud/%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%BB%E6%9C%BA%E6%90%AD%E5%BB%BA-k8s-%E9%9B%86%E7%BE%A4/",
	"title": "阿里云主机搭建 K8S 集群",
	"tags": ["cloud", "k8s"],
	"description": "",
	"content": "通过阿里云ECS实例搭建K8S集群\n环境  阿里云ECS * 2 centos7.4 阿里云两台机器需要内网互通（同一k可用区可以创建免费VPC高速通道实现）  安装 docker 官方文档\nsudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce  配置代理  shadowsocks服务端 provixy shadowsocks客户端 sslocal  安装 shadowsocks yum -y install python-pip pip install shadowsocks  配置 shadowsocks vim /etc/shadowsocks.json  { \u0026quot;server\u0026quot;:\u0026quot;1.1.1.1\u0026quot;, //shadowsocks server ip \u0026quot;server_port\u0026quot;:8888,\t//shadowsocks server port \u0026quot;local_address\u0026quot;: \u0026quot;127.0.0.1\u0026quot;,\t\u0026quot;local_port\u0026quot;:1080,\t//default 1080 \u0026quot;password\u0026quot;:\u0026quot;ssserver_passwd\u0026quot;, \u0026quot;timeout\u0026quot;:300, \u0026quot;method\u0026quot;:\u0026quot;aes-256-cfb\u0026quot;, \u0026quot;fast_open\u0026quot;: false, \u0026quot;workers\u0026quot;: 1 }  安装 privoxy 配置全局代理或 gfwlist 代理\nyum -y install privoxy # 全局代理 echo 'forward-socks5 / 127.0.0.1:1080 .' \u0026gt;\u0026gt;/etc/privoxy/config # gfwlist 代理 # 获取 gfwlist2privoxy 脚本 curl -4sSkL https://raw.github.com/zfl9/gfwlist2privoxy/master/gfwlist2privoxy -O # 生成 gfwlist.action 文件 bash gfwlist2privoxy '127.0.0.1:1080' # 检查 gfwlist.action 文件 more gfwlist.action # 一般有 5000+ 行 # 应用 gfwlist.action 文件 mv -f gfwlist.action /etc/privoxy echo 'actionsfile gfwlist.action' \u0026gt;\u0026gt;/etc/privoxy/config  配置快捷命令 在 /etc/profile.d 新建 set_proxy.sh, linux开机会自动执行该目录下可执行文件\nvim /etc/profile.d/set_proxy.sh  [root@localhost ~]$ cat /etc/profile.d/set_proxy.sh # Initialization script for bash and sh # export proxy for GFW alias proxy_on='nohup sslocal -c /etc/shadowsocks.json \u0026amp; systemctl start privoxy' alias proxy_off='systemctl stop privoxy \u0026amp;\u0026amp; pkill sslocal' alias proxy_export='export http_proxy=http://127.0.0.1:8118 \u0026amp;\u0026amp; export https_proxy=http://127.0.0.1:8118 \u0026amp;\u0026amp; export no_proxy=localhost' alias proxy_unset='unset http_proxy https_proxy no_proxy' alias proxy_test='curl google.com'  手动执行 /etc/profile, 会重新执行/etc/profile.d下文件\nsource /etc/profile  执行alias查看，发现有proxy前缀的别名，则配置成功\n[root@localhost ~]$ alias alias egrep='egrep --color=auto' alias fgrep='fgrep --color=auto' alias grep='grep --color=auto' alias l.='ls -d .* --color=auto' alias ll='ls -l --color=auto' alias ls='ls --color=auto' alias proxy_export='export http_proxy=http://127.0.0.1:8118 \u0026amp;\u0026amp; export https_proxy=http://127.0.0.1:8118 \u0026amp;\u0026amp; export no_proxy=localhost' alias proxy_off='systemctl stop privoxy \u0026amp;\u0026amp; pkill sslocal' alias proxy_on='nohup sslocal -c /etc/shadowsocks.json \u0026amp; systemctl start privoxy' alias proxy_test='curl google.com' alias proxy_unset='unset http_proxy https_proxy no_proxy' alias vi='vim' alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'  执行下面命令开启代理，并配置环境变量(只对当前shell生效，若要永久生效需要在/etc/proxy中export环境变量)\nproxy_on \u0026amp;\u0026amp; proxy_export  执行 proxy_test 测试代理是否配置成功，出现如下输出则配置成功。\n[root@mqd1c2g ~]$ proxy_test \u0026lt;HTML\u0026gt;\u0026lt;HEAD\u0026gt;\u0026lt;meta http-equiv=\u0026quot;content-type\u0026quot; content=\u0026quot;text/html;charset=utf-8\u0026quot;\u0026gt; \u0026lt;TITLE\u0026gt;301 Moved\u0026lt;/TITLE\u0026gt;\u0026lt;/HEAD\u0026gt;\u0026lt;BODY\u0026gt; \u0026lt;H1\u0026gt;301 Moved\u0026lt;/H1\u0026gt; The document has moved \u0026lt;A HREF=\u0026quot;http://www.google.com/\u0026quot;\u0026gt;here\u0026lt;/A\u0026gt;. \u0026lt;/BODY\u0026gt;\u0026lt;/HTML\u0026gt;  参考: ss-local 终端代理（gfwlist）\n安装 Kubernetes 官方文档\n安装kubeadm 检查机器是否符合文档中的Before you begin的要求, 符合的话才能进行接下来的步骤。\ncat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kube* EOF # Set SELinux in permissive mode (effectively disabling it) setenforce 0 sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet  创建 master 节点 # pod-network-cidr 10.244.0.0/16 是后面 flannel 默认配置的 pod Network，配置成这个地址不用改的flannel的 默认配置 kubeadm init --pod-network-cidr 10.244.0.0/16  成功执行后 master 节点就已经启动了, 可以选择安装一种网络插件，这里选择flannel\n# 使用默认配置启动 flannel 的 DaemonSet kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml  创建 node 节点 在 master 节点执行下面命令生成创建子节点命令\nkubeadm token create --print-join-command  [root@localhost ~]$ kubeadm token create --print-join-command kubeadm join masterip:6443 --token 5zk5ql.5eq0rgoui0dl0xx3 --discovery-token-ca-cert-hash sha256:5bef3894fc492bf9d93c9f248f84ec3sdsadasdss7685191a9d841fd32a88bb9ac9  在 node 节点执行上述命令生成的命令\nkubeadm join masterip:6443 --token 5zk5ql.5eq0rgoui0dl0xx3 --discovery-token-ca-cert-hash sha256:5bef3894fc492bf9d93c9f248f84ec3sdsadasdss7685191a9d841fd32a88bb9ac9  执行成功则 node 节点添加成功\n"
},
{
	"uri": "/contact/",
	"title": "Contact",
	"tags": [],
	"description": "",
	"content": " email: maoqidemail@gmail.com "
},
{
	"uri": "/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Maoqide learning.\nrecord.\ncollect.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/cloud/",
	"title": "Cloud",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/golang/",
	"title": "Golangs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/k8s/",
	"title": "K8s",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/notes/",
	"title": "Notes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]